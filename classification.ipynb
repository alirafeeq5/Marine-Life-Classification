{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7187792,"sourceType":"datasetVersion","datasetId":4155562},{"sourceId":3336814,"sourceType":"datasetVersion","datasetId":2015050},{"sourceId":7249459,"sourceType":"datasetVersion","datasetId":4200098}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T18:31:26.124571Z","iopub.execute_input":"2023-12-20T18:31:26.124978Z","iopub.status.idle":"2023-12-20T18:31:26.133166Z","shell.execute_reply.started":"2023-12-20T18:31:26.124950Z","shell.execute_reply":"2023-12-20T18:31:26.131940Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/fall-23-intro-to-vision-dataset/Dataset/classification/train'\nval_dir = '/kaggle/input/fall-23-intro-to-vision-dataset/Dataset/classification/val'","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:25:13.459452Z","iopub.execute_input":"2023-12-20T16:25:13.460603Z","iopub.status.idle":"2023-12-20T16:25:13.464735Z","shell.execute_reply.started":"2023-12-20T16:25:13.460565Z","shell.execute_reply":"2023-12-20T16:25:13.463789Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## **Train Data**","metadata":{}},{"cell_type":"code","source":"folders = os.listdir(train_dir)\nfolders","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:25:16.210239Z","iopub.execute_input":"2023-12-20T16:25:16.211242Z","iopub.status.idle":"2023-12-20T16:25:16.226587Z","shell.execute_reply.started":"2023-12-20T16:25:16.211196Z","shell.execute_reply":"2023-12-20T16:25:16.225708Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['shark', 'Jelly', 'whale', 'tuna', 'fish']"},"metadata":{}}]},{"cell_type":"code","source":"train_data_augmented = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range = 30,\n        shear_range = 0.2,\n        zoom_range = 0.2,\n        horizontal_flip = True,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        fill_mode='nearest'\n)\ntrain_generator = train_data_augmented.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=True \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:25:18.352191Z","iopub.execute_input":"2023-12-20T16:25:18.352570Z","iopub.status.idle":"2023-12-20T16:25:18.411270Z","shell.execute_reply.started":"2023-12-20T16:25:18.352516Z","shell.execute_reply":"2023-12-20T16:25:18.410565Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 1162 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Val Data**","metadata":{}},{"cell_type":"code","source":"valfolders = os.listdir(val_dir)\nvalfolders","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:25:21.811808Z","iopub.execute_input":"2023-12-20T16:25:21.812565Z","iopub.status.idle":"2023-12-20T16:25:21.818751Z","shell.execute_reply.started":"2023-12-20T16:25:21.812519Z","shell.execute_reply":"2023-12-20T16:25:21.817814Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['shark', 'Jelly', 'whale', 'tuna', 'fish']"},"metadata":{}}]},{"cell_type":"code","source":"val_data_generator = ImageDataGenerator(\n                        rescale=1./255\n)\n\nval_generator = val_data_generator.flow_from_directory(\n    val_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False  \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:25:23.753683Z","iopub.execute_input":"2023-12-20T16:25:23.754709Z","iopub.status.idle":"2023-12-20T16:25:23.778099Z","shell.execute_reply.started":"2023-12-20T16:25:23.754671Z","shell.execute_reply":"2023-12-20T16:25:23.777371Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 308 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Load pre-trained ResNet50 model without top classification layers\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the convolutional layers of ResNet50\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:25:26.723898Z","iopub.execute_input":"2023-12-20T16:25:26.724693Z","iopub.status.idle":"2023-12-20T16:25:30.613592Z","shell.execute_reply.started":"2023-12-20T16:25:26.724658Z","shell.execute_reply":"2023-12-20T16:25:30.612493Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Create a new model on top of the pre-trained ResNet50\nXception_modelmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))  \n\n# Compile the model\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // 32,\n    epochs=10,  \n    validation_data=val_generator,\n    validation_steps=val_generator.samples // 32\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:25:36.127109Z","iopub.execute_input":"2023-12-20T16:25:36.127492Z","iopub.status.idle":"2023-12-20T16:28:24.076455Z","shell.execute_reply.started":"2023-12-20T16:25:36.127462Z","shell.execute_reply":"2023-12-20T16:28:24.075405Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/10\n36/36 [==============================] - 25s 485ms/step - loss: 6.4855 - accuracy: 0.3283 - val_loss: 1.3992 - val_accuracy: 0.5694\nEpoch 2/10\n36/36 [==============================] - 16s 438ms/step - loss: 1.3876 - accuracy: 0.4947 - val_loss: 1.1367 - val_accuracy: 0.5243\nEpoch 3/10\n36/36 [==============================] - 16s 435ms/step - loss: 1.4263 - accuracy: 0.5133 - val_loss: 1.7231 - val_accuracy: 0.4757\nEpoch 4/10\n36/36 [==============================] - 16s 437ms/step - loss: 1.2562 - accuracy: 0.5168 - val_loss: 0.8181 - val_accuracy: 0.7292\nEpoch 5/10\n36/36 [==============================] - 16s 432ms/step - loss: 1.2392 - accuracy: 0.5265 - val_loss: 0.7315 - val_accuracy: 0.7500\nEpoch 6/10\n36/36 [==============================] - 16s 437ms/step - loss: 1.0992 - accuracy: 0.5805 - val_loss: 0.9095 - val_accuracy: 0.6042\nEpoch 7/10\n36/36 [==============================] - 16s 440ms/step - loss: 1.0903 - accuracy: 0.5752 - val_loss: 0.8223 - val_accuracy: 0.6493\nEpoch 8/10\n36/36 [==============================] - 16s 434ms/step - loss: 1.0868 - accuracy: 0.5779 - val_loss: 0.7592 - val_accuracy: 0.7743\nEpoch 9/10\n36/36 [==============================] - 15s 426ms/step - loss: 1.0905 - accuracy: 0.5823 - val_loss: 0.8699 - val_accuracy: 0.7188\nEpoch 10/10\n36/36 [==============================] - 16s 441ms/step - loss: 0.9874 - accuracy: 0.6195 - val_loss: 0.7813 - val_accuracy: 0.7396\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model","metadata":{}},{"cell_type":"code","source":"# Define the model\nCNN_Model = Sequential()\n\nCNN_Model.add(Conv2D(16, (3, 3), strides=1, activation='relu', input_shape=(224, 224, 3)))\nCNN_Model.add(MaxPooling2D())\n\nCNN_Model.add(Conv2D(32, (3, 3), strides=1, activation='relu'))\nCNN_Model.add(MaxPooling2D())\n\nCNN_Model.add(Conv2D(16, (3, 3), strides=1, activation='relu'))\nCNN_Model.add(MaxPooling2D())\n\nCNN_Model.add(Flatten())\n\nCNN_Model.add(Dense(256, activation='relu'))  # Adjusted units to match Flatten layer output\nCNN_Model.add(Dense(5, activation='softmax'))  # Assuming 5 output classes, adjust if needed\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:29:15.555278Z","iopub.execute_input":"2023-12-20T16:29:15.555698Z","iopub.status.idle":"2023-12-20T16:29:15.648090Z","shell.execute_reply.started":"2023-12-20T16:29:15.555663Z","shell.execute_reply":"2023-12-20T16:29:15.647337Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Compile the mode\n\nCNN_Model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy']) \ntensorboard_callback =ReduceLROnPlateau(\n    monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:30:00.116580Z","iopub.execute_input":"2023-12-20T16:30:00.117487Z","iopub.status.idle":"2023-12-20T16:30:00.130813Z","shell.execute_reply.started":"2023-12-20T16:30:00.117453Z","shell.execute_reply":"2023-12-20T16:30:00.129960Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"CNN_Model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_CNN = CNN_Model.fit(train_generator, epochs=30, validation_data=val_generator, callbacks=[tensorboard_callback])","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:30:07.460975Z","iopub.execute_input":"2023-12-20T16:30:07.461354Z","iopub.status.idle":"2023-12-20T16:37:59.236359Z","shell.execute_reply.started":"2023-12-20T16:30:07.461321Z","shell.execute_reply":"2023-12-20T16:37:59.235236Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/30\n37/37 [==============================] - 18s 423ms/step - loss: 1.5432 - accuracy: 0.5422 - val_loss: 0.8165 - val_accuracy: 0.7208 - lr: 0.0010\nEpoch 2/30\n37/37 [==============================] - 16s 424ms/step - loss: 0.9747 - accuracy: 0.6351 - val_loss: 2.0923 - val_accuracy: 0.1234 - lr: 0.0010\nEpoch 3/30\n37/37 [==============================] - 16s 431ms/step - loss: 0.9088 - accuracy: 0.6661 - val_loss: 0.6570 - val_accuracy: 0.7468 - lr: 0.0010\nEpoch 4/30\n37/37 [==============================] - 16s 423ms/step - loss: 0.7759 - accuracy: 0.7031 - val_loss: 0.5768 - val_accuracy: 0.7890 - lr: 0.0010\nEpoch 5/30\n37/37 [==============================] - 16s 430ms/step - loss: 0.7765 - accuracy: 0.7091 - val_loss: 0.5922 - val_accuracy: 0.7630 - lr: 0.0010\nEpoch 6/30\n37/37 [==============================] - 16s 422ms/step - loss: 0.7439 - accuracy: 0.7289 - val_loss: 0.5180 - val_accuracy: 0.8084 - lr: 0.0010\nEpoch 7/30\n37/37 [==============================] - 16s 420ms/step - loss: 0.6823 - accuracy: 0.7392 - val_loss: 0.5750 - val_accuracy: 0.7825 - lr: 0.0010\nEpoch 8/30\n37/37 [==============================] - 16s 419ms/step - loss: 0.6793 - accuracy: 0.7298 - val_loss: 0.7117 - val_accuracy: 0.7013 - lr: 0.0010\nEpoch 9/30\n37/37 [==============================] - 16s 422ms/step - loss: 0.6476 - accuracy: 0.7496 - val_loss: 0.4806 - val_accuracy: 0.8182 - lr: 0.0010\nEpoch 10/30\n37/37 [==============================] - 16s 423ms/step - loss: 0.6601 - accuracy: 0.7539 - val_loss: 0.5960 - val_accuracy: 0.7500 - lr: 0.0010\nEpoch 11/30\n37/37 [==============================] - 16s 427ms/step - loss: 0.6429 - accuracy: 0.7487 - val_loss: 0.5313 - val_accuracy: 0.7922 - lr: 0.0010\nEpoch 12/30\n37/37 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.7418\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n37/37 [==============================] - 15s 414ms/step - loss: 0.6937 - accuracy: 0.7418 - val_loss: 0.6797 - val_accuracy: 0.7435 - lr: 0.0010\nEpoch 13/30\n37/37 [==============================] - 16s 423ms/step - loss: 0.5545 - accuracy: 0.7728 - val_loss: 0.4820 - val_accuracy: 0.7955 - lr: 5.0000e-04\nEpoch 14/30\n37/37 [==============================] - 15s 413ms/step - loss: 0.5508 - accuracy: 0.7883 - val_loss: 0.4668 - val_accuracy: 0.7955 - lr: 5.0000e-04\nEpoch 15/30\n37/37 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.7969\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n37/37 [==============================] - 16s 429ms/step - loss: 0.5069 - accuracy: 0.7969 - val_loss: 0.4486 - val_accuracy: 0.8052 - lr: 5.0000e-04\nEpoch 16/30\n37/37 [==============================] - 15s 415ms/step - loss: 0.4672 - accuracy: 0.8115 - val_loss: 0.4701 - val_accuracy: 0.7922 - lr: 2.5000e-04\nEpoch 17/30\n37/37 [==============================] - 16s 426ms/step - loss: 0.4735 - accuracy: 0.8115 - val_loss: 0.4683 - val_accuracy: 0.8117 - lr: 2.5000e-04\nEpoch 18/30\n37/37 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.8193\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n37/37 [==============================] - 15s 415ms/step - loss: 0.4636 - accuracy: 0.8193 - val_loss: 0.4795 - val_accuracy: 0.8084 - lr: 2.5000e-04\nEpoch 19/30\n37/37 [==============================] - 16s 421ms/step - loss: 0.4499 - accuracy: 0.8141 - val_loss: 0.4373 - val_accuracy: 0.8182 - lr: 1.2500e-04\nEpoch 20/30\n37/37 [==============================] - 15s 413ms/step - loss: 0.4359 - accuracy: 0.8296 - val_loss: 0.4505 - val_accuracy: 0.7987 - lr: 1.2500e-04\nEpoch 21/30\n37/37 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.8176\nEpoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n37/37 [==============================] - 16s 419ms/step - loss: 0.4558 - accuracy: 0.8176 - val_loss: 0.4502 - val_accuracy: 0.8052 - lr: 1.2500e-04\nEpoch 22/30\n37/37 [==============================] - 15s 416ms/step - loss: 0.4346 - accuracy: 0.8270 - val_loss: 0.4439 - val_accuracy: 0.8084 - lr: 6.2500e-05\nEpoch 23/30\n37/37 [==============================] - 16s 423ms/step - loss: 0.4263 - accuracy: 0.8339 - val_loss: 0.4496 - val_accuracy: 0.8052 - lr: 6.2500e-05\nEpoch 24/30\n37/37 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.8373\nEpoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n37/37 [==============================] - 15s 414ms/step - loss: 0.4363 - accuracy: 0.8373 - val_loss: 0.4542 - val_accuracy: 0.8052 - lr: 6.2500e-05\nEpoch 25/30\n37/37 [==============================] - 16s 427ms/step - loss: 0.4258 - accuracy: 0.8287 - val_loss: 0.4421 - val_accuracy: 0.8052 - lr: 3.1250e-05\nEpoch 26/30\n37/37 [==============================] - 15s 418ms/step - loss: 0.4233 - accuracy: 0.8279 - val_loss: 0.4362 - val_accuracy: 0.8052 - lr: 3.1250e-05\nEpoch 27/30\n37/37 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8322\nEpoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n37/37 [==============================] - 15s 417ms/step - loss: 0.4270 - accuracy: 0.8322 - val_loss: 0.4481 - val_accuracy: 0.8019 - lr: 3.1250e-05\nEpoch 28/30\n37/37 [==============================] - 15s 415ms/step - loss: 0.4136 - accuracy: 0.8356 - val_loss: 0.4420 - val_accuracy: 0.8052 - lr: 1.5625e-05\nEpoch 29/30\n37/37 [==============================] - 16s 426ms/step - loss: 0.4165 - accuracy: 0.8279 - val_loss: 0.4457 - val_accuracy: 0.8019 - lr: 1.5625e-05\nEpoch 30/30\n37/37 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.8322\nEpoch 30: ReduceLROnPlateau reducing learning rate to 1e-05.\n37/37 [==============================] - 16s 432ms/step - loss: 0.4167 - accuracy: 0.8322 - val_loss: 0.4415 - val_accuracy: 0.8052 - lr: 1.5625e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Xception","metadata":{}},{"cell_type":"code","source":"pretrained_base_model = Xception(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224, 224, 3),\n    classes=5  # 5 classes: fish, jelly, shark, tuna, whale \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T17:52:14.688486Z","iopub.execute_input":"2023-12-20T17:52:14.688885Z","iopub.status.idle":"2023-12-20T17:52:16.120556Z","shell.execute_reply.started":"2023-12-20T17:52:14.688853Z","shell.execute_reply":"2023-12-20T17:52:16.119699Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\n\n\nXception_model = Sequential([\n    pretrained_base_model,\n    GlobalAveragePooling2D(),\n    Dropout(0.5),\n    Flatten(),                       # Adding Flatten layer to transition from 3D to 1D tensor\n    Dense(1024, activation='relu'),  # Additional Dense layer\n    Dropout(0.5),\n    Dense(256, activation='relu'),   # Another Dense layer\n    Dense(5, activation='softmax')   # Output layer for 5 classes\n])\n\n# Compile the model\nXception_model.compile(\n    optimizer=optimizer,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Fit the model with your data\nXception_history = Xception_model.fit(\n    train_generator,\n    epochs=30,\n    batch_size=32,\n    validation_data=val_generator\n\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T17:53:26.425139Z","iopub.execute_input":"2023-12-20T17:53:26.425553Z","iopub.status.idle":"2023-12-20T18:04:21.421865Z","shell.execute_reply.started":"2023-12-20T17:53:26.425503Z","shell.execute_reply":"2023-12-20T18:04:21.420957Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 1/30\n37/37 [==============================] - 41s 593ms/step - loss: 0.7877 - accuracy: 0.6885 - val_loss: 0.3478 - val_accuracy: 0.9026\nEpoch 2/30\n37/37 [==============================] - 22s 588ms/step - loss: 0.2329 - accuracy: 0.9277 - val_loss: 0.1817 - val_accuracy: 0.9610\nEpoch 3/30\n37/37 [==============================] - 21s 560ms/step - loss: 0.1840 - accuracy: 0.9441 - val_loss: 0.2418 - val_accuracy: 0.9545\nEpoch 4/30\n37/37 [==============================] - 21s 550ms/step - loss: 0.1237 - accuracy: 0.9656 - val_loss: 0.3058 - val_accuracy: 0.9545\nEpoch 5/30\n37/37 [==============================] - 21s 559ms/step - loss: 0.1210 - accuracy: 0.9656 - val_loss: 0.7074 - val_accuracy: 0.9156\nEpoch 6/30\n37/37 [==============================] - 21s 566ms/step - loss: 0.0673 - accuracy: 0.9802 - val_loss: 0.4150 - val_accuracy: 0.9643\nEpoch 7/30\n37/37 [==============================] - 21s 564ms/step - loss: 0.0942 - accuracy: 0.9768 - val_loss: 0.3473 - val_accuracy: 0.9610\nEpoch 8/30\n37/37 [==============================] - 21s 558ms/step - loss: 0.0537 - accuracy: 0.9811 - val_loss: 0.3777 - val_accuracy: 0.9513\nEpoch 9/30\n37/37 [==============================] - 21s 559ms/step - loss: 0.0800 - accuracy: 0.9776 - val_loss: 0.4306 - val_accuracy: 0.9578\nEpoch 10/30\n37/37 [==============================] - 21s 563ms/step - loss: 0.0512 - accuracy: 0.9854 - val_loss: 0.3734 - val_accuracy: 0.9675\nEpoch 11/30\n37/37 [==============================] - 21s 563ms/step - loss: 0.0531 - accuracy: 0.9888 - val_loss: 0.5257 - val_accuracy: 0.9610\nEpoch 12/30\n37/37 [==============================] - 21s 561ms/step - loss: 0.0714 - accuracy: 0.9836 - val_loss: 1.4782 - val_accuracy: 0.8961\nEpoch 13/30\n37/37 [==============================] - 21s 559ms/step - loss: 0.0847 - accuracy: 0.9862 - val_loss: 0.6823 - val_accuracy: 0.9578\nEpoch 14/30\n37/37 [==============================] - 21s 560ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.4062 - val_accuracy: 0.9643\nEpoch 15/30\n37/37 [==============================] - 21s 561ms/step - loss: 0.0663 - accuracy: 0.9862 - val_loss: 0.3600 - val_accuracy: 0.9643\nEpoch 16/30\n37/37 [==============================] - 21s 562ms/step - loss: 0.0390 - accuracy: 0.9923 - val_loss: 0.4744 - val_accuracy: 0.9513\nEpoch 17/30\n37/37 [==============================] - 21s 562ms/step - loss: 0.0425 - accuracy: 0.9897 - val_loss: 0.5573 - val_accuracy: 0.9545\nEpoch 18/30\n37/37 [==============================] - 21s 563ms/step - loss: 0.0384 - accuracy: 0.9923 - val_loss: 0.5604 - val_accuracy: 0.9513\nEpoch 19/30\n37/37 [==============================] - 21s 560ms/step - loss: 0.0337 - accuracy: 0.9914 - val_loss: 0.4631 - val_accuracy: 0.9481\nEpoch 20/30\n37/37 [==============================] - 21s 559ms/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 0.5269 - val_accuracy: 0.9578\nEpoch 21/30\n37/37 [==============================] - 21s 559ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 0.5088 - val_accuracy: 0.9448\nEpoch 22/30\n37/37 [==============================] - 21s 560ms/step - loss: 0.0514 - accuracy: 0.9914 - val_loss: 0.3072 - val_accuracy: 0.9708\nEpoch 23/30\n37/37 [==============================] - 21s 560ms/step - loss: 0.0704 - accuracy: 0.9854 - val_loss: 0.6018 - val_accuracy: 0.9545\nEpoch 24/30\n37/37 [==============================] - 21s 559ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.4674 - val_accuracy: 0.9448\nEpoch 25/30\n37/37 [==============================] - 21s 563ms/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 0.5734 - val_accuracy: 0.9123\nEpoch 26/30\n37/37 [==============================] - 21s 564ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.8482 - val_accuracy: 0.9253\nEpoch 27/30\n37/37 [==============================] - 21s 560ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.5524 - val_accuracy: 0.9513\nEpoch 28/30\n37/37 [==============================] - 21s 561ms/step - loss: 0.0335 - accuracy: 0.9931 - val_loss: 0.7293 - val_accuracy: 0.9545\nEpoch 29/30\n37/37 [==============================] - 21s 559ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.7525 - val_accuracy: 0.9481\nEpoch 30/30\n37/37 [==============================] - 21s 561ms/step - loss: 0.0229 - accuracy: 0.9957 - val_loss: 0.4329 - val_accuracy: 0.9675\n","output_type":"stream"}]},{"cell_type":"code","source":"Xception_model.save('/kaggle/working/Xception_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T18:10:33.826326Z","iopub.execute_input":"2023-12-20T18:10:33.827111Z","iopub.status.idle":"2023-12-20T18:10:34.540398Z","shell.execute_reply.started":"2023-12-20T18:10:33.827073Z","shell.execute_reply":"2023-12-20T18:10:34.539386Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n\n\ndef classify_moves(move_folder, saved_model_path, class_names):\n    # Load the saved model\n    loaded_model = load_model(saved_model_path)\n\n    move_images = os.listdir(move_folder)\n    move_images.sort()  # Sort for consistent ordering\n\n    for move_image in move_images:\n        image_path = os.path.join(move_folder, move_image)\n        # Pre-processing\n        img_size = 224  # Assuming the model was trained on images of this size\n        img = image.load_img(image_path, target_size=(img_size, img_size))\n        img_array = image.img_to_array(img)\n        img_array = np.expand_dims(img_array, axis=0)\n        img_array /= 255.0  # Rescale\n\n        # Make predictions on the single image\n        predictions = loaded_model.predict(img_array)\n\n        # Map predictions to class labels\n        predicted_class_index = np.argmax(predictions, axis=1)[0]\n        predicted_class = class_names[predicted_class_index]\n\n        print(f\"Image: {move_image} - Predicted Move: {predicted_class}\")\n\n# ************************************test*********************************\nmove_folder_path = '/kaggle/input/test-fish/TestClassification'\nsaved_model_path = '/kaggle/working/Xception_model.h5'\nclass_names = ['Jelly', 'fish', 'shark', 'tuna', 'whale'] \n\nclassify_moves(move_folder_path, saved_model_path, class_names)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T18:29:55.398252Z","iopub.execute_input":"2023-12-20T18:29:55.398817Z","iopub.status.idle":"2023-12-20T18:29:59.643143Z","shell.execute_reply.started":"2023-12-20T18:29:55.398779Z","shell.execute_reply":"2023-12-20T18:29:59.642251Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 1s/step\nImage: 48.jpg - Predicted Move: fish\n1/1 [==============================] - 0s 23ms/step\nImage: 8.jpg - Predicted Move: fish\n1/1 [==============================] - 0s 22ms/step\nImage: v_105.jpg - Predicted Move: Jelly\n1/1 [==============================] - 0s 22ms/step\nImage: v_106.jpg - Predicted Move: shark\n1/1 [==============================] - 0s 22ms/step\nImage: v_130.jpg - Predicted Move: shark\n1/1 [==============================] - 0s 22ms/step\nImage: v_131.jpg - Predicted Move: shark\n1/1 [==============================] - 0s 21ms/step\nImage: v_137.jpg - Predicted Move: tuna\n1/1 [==============================] - 0s 22ms/step\nImage: v_141.jpg - Predicted Move: tuna\n1/1 [==============================] - 0s 21ms/step\nImage: v_169.jpg - Predicted Move: whale\n1/1 [==============================] - 0s 21ms/step\nImage: v_175.jpg - Predicted Move: whale\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## VGG19","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG19\n\n\n# Define the pre-trained VGG19 model\npretrained_base_model = VGG19(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224, 224, 3),\n    classes=5  # 5 classes: fish, jelly, shark, tuna, whale \n)\n\n# Freeze the pre-trained layers\nfor layer in pretrained_base_model.layers:\n    layer.trainable = False\n\n# Create a new model on top\nVGG19_model = Sequential([\n    pretrained_base_model,\n    GlobalAveragePooling2D(),\n    Dropout(0.5),\n    Dense(5, activation='softmax')  # 5 classes: fish, jelly, shark, tuna, whale\n])\n\n# Compile the model\nVGG19_model.compile(\n    optimizer=RMSprop(),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Fit the model with your data\nhistory = VGG19_model.fit(\n    train_generator,\n    epochs=20,\n    batch_size=32,\n    validation_data=val_generator\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T17:05:02.377166Z","iopub.execute_input":"2023-12-20T17:05:02.377515Z","iopub.status.idle":"2023-12-20T17:10:48.851078Z","shell.execute_reply.started":"2023-12-20T17:05:02.377485Z","shell.execute_reply":"2023-12-20T17:10:48.850062Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/20\n37/37 [==============================] - 18s 466ms/step - loss: 1.5609 - accuracy: 0.3296 - val_loss: 1.1145 - val_accuracy: 0.7240\nEpoch 2/20\n37/37 [==============================] - 17s 465ms/step - loss: 1.3424 - accuracy: 0.4587 - val_loss: 1.0129 - val_accuracy: 0.6981\nEpoch 3/20\n37/37 [==============================] - 17s 460ms/step - loss: 1.2144 - accuracy: 0.5327 - val_loss: 0.9357 - val_accuracy: 0.7630\nEpoch 4/20\n37/37 [==============================] - 17s 454ms/step - loss: 1.1193 - accuracy: 0.5998 - val_loss: 0.8278 - val_accuracy: 0.7662\nEpoch 5/20\n37/37 [==============================] - 17s 461ms/step - loss: 1.0630 - accuracy: 0.6093 - val_loss: 0.7658 - val_accuracy: 0.8019\nEpoch 6/20\n37/37 [==============================] - 17s 461ms/step - loss: 1.0290 - accuracy: 0.6377 - val_loss: 0.7224 - val_accuracy: 0.8182\nEpoch 7/20\n37/37 [==============================] - 17s 464ms/step - loss: 0.9633 - accuracy: 0.6738 - val_loss: 0.6946 - val_accuracy: 0.8117\nEpoch 8/20\n37/37 [==============================] - 18s 478ms/step - loss: 0.9204 - accuracy: 0.6928 - val_loss: 0.6607 - val_accuracy: 0.7922\nEpoch 9/20\n37/37 [==============================] - 17s 467ms/step - loss: 0.8898 - accuracy: 0.7126 - val_loss: 0.6298 - val_accuracy: 0.8149\nEpoch 10/20\n37/37 [==============================] - 17s 461ms/step - loss: 0.8921 - accuracy: 0.7014 - val_loss: 0.6076 - val_accuracy: 0.8312\nEpoch 11/20\n37/37 [==============================] - 17s 460ms/step - loss: 0.8663 - accuracy: 0.7134 - val_loss: 0.5931 - val_accuracy: 0.8117\nEpoch 12/20\n37/37 [==============================] - 17s 463ms/step - loss: 0.8130 - accuracy: 0.7306 - val_loss: 0.5767 - val_accuracy: 0.8247\nEpoch 13/20\n37/37 [==============================] - 17s 461ms/step - loss: 0.8234 - accuracy: 0.7134 - val_loss: 0.5645 - val_accuracy: 0.8312\nEpoch 14/20\n37/37 [==============================] - 17s 467ms/step - loss: 0.8005 - accuracy: 0.7306 - val_loss: 0.5469 - val_accuracy: 0.8377\nEpoch 15/20\n37/37 [==============================] - 17s 459ms/step - loss: 0.7863 - accuracy: 0.7410 - val_loss: 0.5331 - val_accuracy: 0.8377\nEpoch 16/20\n37/37 [==============================] - 17s 459ms/step - loss: 0.7630 - accuracy: 0.7582 - val_loss: 0.5364 - val_accuracy: 0.8377\nEpoch 17/20\n37/37 [==============================] - 17s 458ms/step - loss: 0.7662 - accuracy: 0.7384 - val_loss: 0.5377 - val_accuracy: 0.8214\nEpoch 18/20\n37/37 [==============================] - 18s 471ms/step - loss: 0.7636 - accuracy: 0.7418 - val_loss: 0.5126 - val_accuracy: 0.8377\nEpoch 19/20\n37/37 [==============================] - 17s 463ms/step - loss: 0.7562 - accuracy: 0.7453 - val_loss: 0.4961 - val_accuracy: 0.8474\nEpoch 20/20\n37/37 [==============================] - 17s 460ms/step - loss: 0.7560 - accuracy: 0.7367 - val_loss: 0.4874 - val_accuracy: 0.8506\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}